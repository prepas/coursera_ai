import pandas
import math
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import log_loss
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier

data = pandas.read_csv('C:\\Users\\prepodobniy\\Desktop\\gbm-data.csv')
print(data)
X = data.loc[:, 'D1':'D1776']
y = data['Activity']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=241)
list = [0.2] #[1, 0.5, 0.3, 0.2, 0.1]
for i in list:
    kn = GradientBoostingClassifier(n_estimators=250, verbose=True, random_state=241, learning_rate=i)
    kn.fit(X_train, y_train)
    scores_train = []
    for k in kn.staged_decision_function(X_train):
        scores_train.append(log_loss(y_train, [1.0/(1.0+math.exp(-i)) for i in k]))
        
    scores_test = []
    for k in kn.staged_decision_function(X_test):
        scores_test.append(log_loss(y_test, [1.0/(1.0+math.exp(-i)) for i in k]))
    
    m = min(scores_test)
    print('min log-loss=', m)
    print('index=', scores_test.index(m) + 1)
    plt.figure()
    plt.plot(scores_test, 'r', linewidth=2)
    plt.plot(scores_train, 'g', linewidth=2)
    plt.legend(['test', 'train']) 

clf = RandomForestClassifier(n_estimators=37, random_state=241)
clf.fit(X_train, y_train)
print('forest log-loss=', log_loss(y_test, clf.predict_proba(X_test)))